"use strict";(self.webpackChunkais_project_github_io=self.webpackChunkais_project_github_io||[]).push([[387],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>f});var s=t(7294);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);a&&(s=s.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,s)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,s,n=function(e,a){if(null==e)return{};var t,s,n={},r=Object.keys(e);for(s=0;s<r.length;s++)t=r[s],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(s=0;s<r.length;s++)t=r[s],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var d=s.createContext({}),l=function(e){var a=s.useContext(d),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},p=function(e){var a=l(e.components);return s.createElement(d.Provider,{value:a},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var a=e.children;return s.createElement(s.Fragment,{},a)}},u=s.forwardRef((function(e,a){var t=e.components,n=e.mdxType,r=e.originalType,d=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=l(t),u=n,f=c["".concat(d,".").concat(u)]||c[u]||m[u]||r;return t?s.createElement(f,o(o({ref:a},p),{},{components:t})):s.createElement(f,o({ref:a},p))}));function f(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var r=t.length,o=new Array(r);o[0]=u;var i={};for(var d in a)hasOwnProperty.call(a,d)&&(i[d]=a[d]);i.originalType=e,i[c]="string"==typeof e?e:n,o[1]=i;for(var l=2;l<r;l++)o[l]=t[l];return s.createElement.apply(null,o)}return s.createElement.apply(null,t)}u.displayName="MDXCreateElement"},9459:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>d,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>l});var s=t(7462),n=(t(7294),t(3905));const r={sidebar_position:1,title:"Usando o BNSA",sidebar_label:"Usando o BNSA",lastUpdatedAt:"2023/06/01",author:"Jo\xe3o Paulo",showLastUpdateAuthor:!0,showLastUpdateTime:!0,last_update:{date:"2023/06/01",author:"Jo\xe3o Paulo"}},o="Usando o BNSA",i={unversionedId:"Getting Started/basic use/BNSA",id:"Getting Started/basic use/BNSA",title:"Usando o BNSA",description:"Acesse o notebook Jupyter com o c\xf3digo dispon\xedvel aqui!",source:"@site/i18n/pt-br/docusaurus-plugin-content-docs/current/Getting Started/basic use/BNSA.md",sourceDirName:"Getting Started/basic use",slug:"/Getting Started/basic use/BNSA",permalink:"/pt-br/docs/Getting Started/basic use/BNSA",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"Usando o BNSA",sidebar_label:"Usando o BNSA",lastUpdatedAt:"2023/06/01",author:"Jo\xe3o Paulo",showLastUpdateAuthor:!0,showLastUpdateTime:!0,last_update:{date:"2023/06/01",author:"Jo\xe3o Paulo"}},sidebar:"tutorialSidebar",previous:{title:"Instala\xe7\xe3o",permalink:"/pt-br/docs/Getting Started/instalation"},next:{title:"Usando o RNSA",permalink:"/pt-br/docs/Getting Started/basic use/RNSA"}},d={},l=[{value:"Importando o Algoritmo de sele\xe7\xe3o negativa bin\xe1ria.",id:"importando-o-algoritmo-de-sele\xe7\xe3o-negativa-bin\xe1ria",level:2},{value:"Gerando amostras bin\xe1rias aleatoriamente e separando os dados.",id:"gerando-amostras-bin\xe1rias-aleatoriamente-e-separando-os-dados",level:2},{value:"Fun\xe7\xe3o para gerar amostras bin\xe1rias",id:"fun\xe7\xe3o-para-gerar-amostras-bin\xe1rias",level:3},{value:"Gera\xe7\xe3o e separa\xe7\xe3o de dados",id:"gera\xe7\xe3o-e-separa\xe7\xe3o-de-dados",level:3},{value:"Testando o modelo:",id:"testando-o-modelo",level:2},{value:"Matriz de confus\xe3o",id:"matriz-de-confus\xe3o",level:2}],p={toc:l},c="wrapper";function m(e){let{components:a,...r}=e;return(0,n.kt)(c,(0,s.Z)({},p,r,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"usando-o-bnsa"},"Usando o BNSA"),(0,n.kt)("p",null,"Acesse o notebook Jupyter com o c\xf3digo dispon\xedvel ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/AIS-Package/aisp/blob/main/examples/BNSA/example_with_randomly_generated_dataset-pt.ipynb"},"aqui"),"!"),(0,n.kt)("h2",{id:"importando-o-algoritmo-de-sele\xe7\xe3o-negativa-bin\xe1ria"},"Importando o Algoritmo de sele\xe7\xe3o negativa bin\xe1ria."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"from aisp.NSA import BNSA\n")),(0,n.kt)("h2",{id:"gerando-amostras-bin\xe1rias-aleatoriamente-e-separando-os-dados"},"Gerando amostras bin\xe1rias aleatoriamente e separando os dados."),(0,n.kt)("h3",{id:"fun\xe7\xe3o-para-gerar-amostras-bin\xe1rias"},"Fun\xe7\xe3o para gerar amostras bin\xe1rias"),(0,n.kt)("p",null,"Nesta fun\xe7\xe3o, s\xe3o geradas amostras de dados bin\xe1rios com um grau de similaridade abaixo do limiar definido s. No entanto, 10% dos primeiros dados s\xe3o gerados aleatoriamente, sem levar em considera\xe7\xe3o o valor de s. Al\xe9m disso, quando j\xe1 existem amostras, s\xe3o geradas amostras \xfanicas para a nova classe, garantindo que as amostras aleat\xf3rias geradas n\xe3o estejam duplicadas em classes diferentes."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"import numpy as np\nfrom scipy.spatial.distance import cdist\n# Essa fun\xe7\xe3o gera amostras com similaridades acima de um limiar de semelhan\xe7a.\ndef generate_samples(n_samples: int, n_features: int, s: float, x: None):\n  classe_samples = []\n  while len(classe_samples) < n_samples:\n    similarity = 0\n    sample_rand = np.random.randint(0, 2, size=(n_features))\n    if(len(classe_samples) > max(int(n_samples * 0.1), 1)):\n      similarity = cdist(classe_samples, np.expand_dims(sample_rand, axis=0), metric='hamming')[0, :]\n      if x is not None:\n        if similarity[0] <= s and not np.any(np.all(sample_rand == x, axis=1)):\n          classe_samples.append(sample_rand)\n      elif similarity[0] <= s:\n        classe_samples.append(sample_rand)\n    else:\n      classe_samples.append(sample_rand)\n  return np.array(classe_samples)\n")),(0,n.kt)("hr",null),(0,n.kt)("h3",{id:"gera\xe7\xe3o-e-separa\xe7\xe3o-de-dados"},"Gera\xe7\xe3o e separa\xe7\xe3o de dados"),(0,n.kt)("p",null,"Nessa etapa, s\xe3o gerados 1000 dados, sendo 500 para representar a classe 'x' e 500 para representar a classe 'y'. Cada dado \xe9 formado por 20 dimens\xf5es. \xc9 importante destacar que esses dados s\xe3o criados de forma que apresentem um grau de similaridade de 80%, ou seja, compartilham caracter\xedsticas comuns. Ap\xf3s a gera\xe7\xe3o, os dados s\xe3o separados em conjuntos de treinamento e teste."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'# Configurando a seed para 121 para garantir a reprodutibilidade dos dados gerados.\nnp.random.seed(121)\n# Gerando amostras para a classe "x".\nx = generate_samples(500, 20, 0.2, None)\n# Gerando amostras exclusivas para a classe "y", diferentes das amostras presentes na classe "x".\ny = generate_samples(500, 20, 0.2, x)\n# Adicionando colunas contendo as sa\xeddas (r\xf3tulos) das classes "x" e "y".\nx = np.hstack((x, np.full((x.shape[0], 1), \'x\')))\ny = np.hstack((y, np.full((y.shape[0], 1), \'y\')))\n# Juntando os dois vetores (classes "x" e "y") e randomizando a ordem das amostras.\nindex = np.random.permutation(x.shape[0]*2)\ndataset = np.vstack((x, y))[index]\n\n# Separando as caracter\xedsticas (inputs) e as classes de sa\xedda (r\xf3tulos).\nsamples = dataset[:, :-1].astype(int)\noutput = dataset[:, -1]\n# Separating data for training and testing.\ntrain_x, test_x, train_y, test_y = train_test_split(samples, output, test_size=0.2, random_state=1234321)\n\n')),(0,n.kt)("hr",null),(0,n.kt)("h2",{id:"testando-o-modelo"},"Testando o modelo:"),(0,n.kt)("p",null,"Iniciando o modelo e aplicando-o \xe0s amostras geradas aleatoriamente, a configura\xe7\xe3o atual possui 250 detectores com uma taxa de diferencia\xe7\xe3o de 30%."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'# Iniciando p modelo.\nnsa = BNSA(N=250, aff_thresh=0.34, seed=1234321, max_discards=10000)\n# Efetuando o treinamento: \nnsa.fit(X=train_x, y=train_y)\n# Efetuando a previs\xe3o:: \nprev = nsa.predict(X=test_x)\n# Mostrando a acur\xe1cia das previs\xf5es para os dados reais.\nprint(f"A acur\xe1cia \xe9 {accuracy_score(prev, test_y)}")\nprint(classification_report(test_y, prev))\n')),(0,n.kt)("p",null,"Output:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\u2714 Non-self detectors for classes (x, y) successfully generated:  \u2507\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2507 500/500 detectors\nA acur\xe1cia \xe9 0.96\n              precision    recall  f1-score   support\n\n           x       0.95      0.97      0.96        90\n           y       0.97      0.95      0.96       110\n\n    accuracy                           0.96       200\n   macro avg       0.96      0.96      0.96       200\nweighted avg       0.96      0.96      0.96       200\n")),(0,n.kt)("hr",null),(0,n.kt)("h2",{id:"matriz-de-confus\xe3o"},"Matriz de confus\xe3o"),(0,n.kt)("p",null,"Aqui est\xe1 a matriz de confus\xe3o, onde a diagonal principal representa as amostras previstas corretamente e a diagonal secund\xe1ria mostra os falsos positivos. Dos 200 dados de teste, houve 5 falsos positivos para a classe x e 6 falsos positivos para a classe y."),(0,n.kt)("p",null,(0,n.kt)("img",{src:t(1214).Z,width:"447",height:"447"})))}m.isMDXComponent=!0},1214:(e,a,t)=>{t.d(a,{Z:()=>s});const s=t.p+"assets/images/matrizBNSA-4024f3e29888b7456c9a8477d4a11313.png"}}]);