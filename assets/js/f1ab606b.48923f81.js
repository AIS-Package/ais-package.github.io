"use strict";(self.webpackChunkais_project_github_io=self.webpackChunkais_project_github_io||[]).push([[606],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>g});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var o=n.createContext({}),c=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(o.Provider,{value:t},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,o=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=c(a),u=r,g=d["".concat(o,".").concat(u)]||d[u]||m[u]||s;return a?n.createElement(g,i(i({ref:t},p),{},{components:a})):n.createElement(g,i({ref:t},p))}));function g(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,i=new Array(s);i[0]=u;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l[d]="string"==typeof e?e:r,i[1]=l;for(var c=2;c<s;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},2168:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>i,default:()=>m,frontMatter:()=>s,metadata:()=>l,toc:()=>c});var n=a(7462),r=(a(7294),a(3905));const s={sidebar_position:2,title:"Basic usage",sidebar_label:"Basic usage",lastUpdatedAt:"2023/06/01",author:"Jo\xe3o Paulo",showLastUpdateAuthor:!0,showLastUpdateTime:!0,last_update:{date:"2023/06/01",author:"Jo\xe3o Paulo"}},i="Basic usage",l={unversionedId:"Getting Started/basic use",id:"Getting Started/basic use",title:"Basic usage",description:"BNSA (Binary Negative Selection Algorithm)",source:"@site/docs/Getting Started/basic use.md",sourceDirName:"Getting Started",slug:"/Getting Started/basic use",permalink:"/docs/Getting Started/basic use",draft:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,title:"Basic usage",sidebar_label:"Basic usage",lastUpdatedAt:"2023/06/01",author:"Jo\xe3o Paulo",showLastUpdateAuthor:!0,showLastUpdateTime:!0,last_update:{date:"2023/06/01",author:"Jo\xe3o Paulo"}},sidebar:"tutorialSidebar",previous:{title:"Instalation",permalink:"/docs/Getting Started/instalation"},next:{title:"Implemented techniques",permalink:"/docs/aisp-techniques/"}},o={},c=[{value:"BNSA (Binary Negative Selection Algorithm)",id:"bnsa-binary-negative-selection-algorithm",level:2},{value:"Importing Binary Negative Selection Algorithm.",id:"importing-binary-negative-selection-algorithm",level:3},{value:"Randomly generating binary samples and splitting the data.",id:"randomly-generating-binary-samples-and-splitting-the-data",level:3},{value:"Function to generate binary samples",id:"function-to-generate-binary-samples",level:4},{value:"Data generation and separation",id:"data-generation-and-separation",level:4},{value:"Testing the model:",id:"testing-the-model",level:3},{value:"RNSA (Real-Valued Negative Selection Algorithm)",id:"rnsa-real-valued-negative-selection-algorithm",level:2},{value:"Importing the Real-Valued Negative Selection Algorithm.",id:"importing-the-real-valued-negative-selection-algorithm",level:3},{value:"Randomly generating class bubbles and separating the data.",id:"randomly-generating-class-bubbles-and-separating-the-data",level:3},{value:"Testing the model <code>default-NSA</code>:",id:"testing-the-model-default-nsa",level:3},{value:"Detector and sample plotting:",id:"detector-and-sample-plotting",level:3},{value:"Testing the model <code>V-detector</code>:",id:"testing-the-model-v-detector",level:3},{value:"Detector and sample plotting:",id:"detector-and-sample-plotting-1",level:3}],p={toc:c},d="wrapper";function m(e){let{components:t,...s}=e;return(0,r.kt)(d,(0,n.Z)({},p,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"basic-usage"},"Basic usage"),(0,r.kt)("h2",{id:"bnsa-binary-negative-selection-algorithm"},"BNSA (Binary Negative Selection Algorithm)"),(0,r.kt)("h3",{id:"importing-binary-negative-selection-algorithm"},"Importing Binary Negative Selection Algorithm."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from aisp.NSA import BNSA\n")),(0,r.kt)("h3",{id:"randomly-generating-binary-samples-and-splitting-the-data"},"Randomly generating binary samples and splitting the data."),(0,r.kt)("h4",{id:"function-to-generate-binary-samples"},"Function to generate binary samples"),(0,r.kt)("p",null,"In this function, samples of binary data with a degree of similarity above a defined threshold s are generated. However, the first 10% of the data is generated randomly, without taking into account the value of s. Furthermore, when there are already samples, unique samples are generated for the new class, ensuring that the random samples generated are not duplicated in different classes."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import numpy as np\nfrom scipy.spatial.distance import cdist\n# This function generates samples with similarities above a similarity threshold.\ndef generate_samples(n_samples: int, n_features: int, s: float, x: None):\n   class_samples = []\n   while len(class_samples) < n_samples:\n     similarity = 0\n     sample_rand = np.random.randint(0, 2, size=(n_features))\n     if(len(class_samples) > max(int(n_samples * 0.1), 1)):\n       similarity = cdist(class_samples, np.expand_dims(sample_rand, axis=0), metric='hamming')[0, :]\n       if x is not None:\n         if similarity[0] > s and not np.any(np.all(sample_rand == x, axis=1)):\n           class_samples.append(sample_rand)\n       elif similarity[0] > s:\n         class_samples.append(sample_rand)\n     else:\n       class_samples.append(sample_rand)\n   return np.array(class_samples)\n")),(0,r.kt)("h4",{id:"data-generation-and-separation"},"Data generation and separation"),(0,r.kt)("p",null,"In this step, 600 pieces of data are generated, 300 representing class 'x' and 300 representing class 'y'. Each die is made up of 20 dimensions. It is important to highlight that these data are created in such a way that they present a degree of similarity of 70%, that is, they share common characteristics. After generation, the data is separated into training and test sets."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\n# Setting the seed to 121 to ensure the reproducibility of the generated data.\nnp.random.seed(121)\n# Generating samples for class "x".\nx = generate_samples(300, 20, 0.7, None)\n# Generating unique samples for class "y", different from samples present in class "x".\ny = generate_samples(300, 20, 0.7, x)\n# Adding columns containing the outputs (labels) of classes "x" and "y".\nx = np.hstack((x, np.full((x.shape[0], 1), \'x\')))\ny = np.hstack((y, np.full((y.shape[0], 1), \'y\')))\n# Merging the two vectors (classes "x" and "y") and randomizing the order of the samples.\nindex = np.random.permutation(x.shape[0]*2)\ndataset = np.vstack((x, y))[index]\n# Separating the characteristics (inputs) and the output classes (labels).\nsamples = dataset[:, :-1].astype(int)\noutput = dataset[:, -1]\n# Data separation for training and testing.\ntrain_x, test_x, train_y, test_y = train_test_split(samples, output, test_size=0.2)\n\n')),(0,r.kt)("h3",{id:"testing-the-model"},"Testing the model:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Starting the model.\nnsa = BNSA(N=100, aff_thresh=0.3, seed=12321, max_discards=10000)\n# Conducting the training:\nnsa.fit(X=train_x, y=train_y)\n# Visualization of classes with test samples.\nprev_y = nsa.predict(test_x)\n# Showing the accuracy of predictions for real data.\nprint(f"The accuracy is {accuracy_score(prev_y, test_y)}")\nprint(classification_report(test_y, prev_y))\n')),(0,r.kt)("p",null,"Output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"\u2714 Non-self detectors for classes (x, y) successfully generated:  \u2507\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2507 200/200 detectors\nThe accuracy is  0.9\n              precision    recall  f1-score   support\n\n           x       0.91      0.91      0.91        68\n           y       0.88      0.88      0.88        52\n\n    accuracy                           0.90       120\n   macro avg       0.90      0.90      0.90       120\nweighted avg       0.90      0.90      0.90       120\n")),(0,r.kt)("h2",{id:"rnsa-real-valued-negative-selection-algorithm"},"RNSA (Real-Valued Negative Selection Algorithm)"),(0,r.kt)("h3",{id:"importing-the-real-valued-negative-selection-algorithm"},"Importing the Real-Valued Negative Selection Algorithm."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from aisp.NSA import RNSA\n")),(0,r.kt)("h3",{id:"randomly-generating-class-bubbles-and-separating-the-data"},"Randomly generating class bubbles and separating the data."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from sklearn.datasets import make_blobs\nfrom sklearn.model_selection import train_test_split\n\n# Generating the samples and outputs for the training.\nsamples, output = make_blobs(n_samples=500 , n_features=2, cluster_std=0.07, center_box=([0.0, 1.0]), centers=[[0.25, 0.75], [0.75, 0.25]], random_state=1234) \n# Separating data for training and testing.\ntrain_x, test_x, train_y, test_y = train_test_split(samples, output, test_size=0.2)\n")),(0,r.kt)("h3",{id:"testing-the-model-default-nsa"},"Testing the model ",(0,r.kt)("inlineCode",{parentName:"h3"},"default-NSA"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\n# Starting the class.\nmodel = RNSA(N=500, r=0.06, seed=123)\n# Carrying out the training:\nmodel.fit(X=train_x, y=train_y)\n# Previewing classes with test samples.\nprev_y = model.predict(test_x)\n# Showing the accuracy of predictions for actual data.\nprint(f"The accuracy is {accuracy_score(prev_y, test_y)}")\nprint(classification_report(test_y, prev_y))\n')),(0,r.kt)("p",null,"Output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"\u2714 Non-self detectors for classes (0, 1) successfully generated:  \u2507\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2507 1000/1000 detectors\nThe accuracy is 1.0\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        55\n           1       1.00      1.00      1.00        45\n\n    accuracy                           1.00       100\n   macro avg       1.00      1.00      1.00       100\nweighted avg       1.00      1.00      1.00       100\n")),(0,r.kt)("h3",{id:"detector-and-sample-plotting"},"Detector and sample plotting:"),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(820).Z,width:"1242",height:"572"})),(0,r.kt)("h3",{id:"testing-the-model-v-detector"},"Testing the model ",(0,r.kt)("inlineCode",{parentName:"h3"},"V-detector"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\n# Starting the class.\nmodel = RNSA(N=20, r=0.02, algorithm='V-detector', r_s=0.04, seed=123)\n# Carrying out the training:\nmodel.fit(X=train_x, y=train_y)\n# Previewing classes with test samples.\nprev_y = model.predict(test_x)\n# Showing the accuracy of predictions for actual data.\nprint(f\"The accuracy is {accuracy_score(prev_y, test_y)}\")\nprint(classification_report(test_y, prev_y))\n")),(0,r.kt)("p",null,"Output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"\u2714 Non-self detectors for classes (0, 1) successfully generated:  \u2507\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2507 40/40 detectors\nThe accuracy is 1.0\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        55\n           1       1.00      1.00      1.00        45\n\n    accuracy                           1.00       100\n   macro avg       1.00      1.00      1.00       100\nweighted avg       1.00      1.00      1.00       100\n")),(0,r.kt)("h3",{id:"detector-and-sample-plotting-1"},"Detector and sample plotting:"),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(5636).Z,width:"1225",height:"593"})))}m.isMDXComponent=!0},820:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/exemple_en_d-44cd95d8dc6321aa646a678c0159130a.png"},5636:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/exemple_en_v-6aa6177affc6e1a660ba8e62cd87118b.png"}}]);